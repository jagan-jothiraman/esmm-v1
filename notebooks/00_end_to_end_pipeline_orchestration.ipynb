{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End ESMM Recommender Pipeline Orchestration\n",
    "\n",
    "This notebook demonstrates the orchestration of the ESMM recommender pipeline using the refactored scripts. It covers:\n",
    "1. **Configuration**: Setting up mock paths and parameters.\n",
    "2. **Data Preparation**: Simulating daily data splitting.\n",
    "3. **EasyRec Configuration Generation**: Creating the pipeline config file for EasyRec training.\n",
    "4. **Model Training (Simulated)**: Showing how EasyRec training would be invoked.\n",
    "5. **Model Evaluation**: Calculating Group AUC on mock prediction data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import subprocess\n",
    "\n",
    "# Add src to Python path to allow direct imports\n",
    "module_path = os.path.abspath(os.path.join('..', 'src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    print(f\"Added {module_path} to sys.path\")\n",
    "\n",
    "try:\n",
    "    # Import refactored functions/modules\n",
    "    from data_processing.split_dataset import perform_split, list_parquet_files_in_gcs_directory, read_parquet_from_gcs as read_mock_parquet_gcs_split, write_df_to_parquet_gcs as write_mock_parquet_gcs_split\n",
    "    from data_processing.auto_feature_config_generator import load_sample_from_gcs_parquet, classify_features, generate_input_fields_proto, generate_feature_config_proto, get_sample_dataframe\n",
    "    from training.generate_and_run_train import group_features, populate_and_save_config # Using populate_and_save_config directly\n",
    "    from evaluation.evaluate_model import create_mock_prediction_file, calculate_group_auc\n",
    "    print(\"Successfully imported pipeline modules and functions.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing modules: {e}\")\n",
    "    print(\"Ensure all scripts have been refactored correctly and 'src' is accessible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Configuration\n",
    "\n",
    "Define mock GCS paths, processing date, split fractions, config file paths, column names, and other parameters for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- General Configuration ---\n",
    "DATE_TO_PROCESS = \"20231101\"\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# --- Mock GCS Paths ---\n",
    "MOCK_GCS_BASE_BUCKET = \"gs://mock-esmm-recommender-bucket\"\n",
    "MOCK_GCS_RAW_DATA_PATH = os.path.join(MOCK_GCS_BASE_BUCKET, \"raw_data\")\n",
    "MOCK_GCS_PROCESSED_DATA_PATH_PREFIX = os.path.join(MOCK_GCS_BASE_BUCKET, \"processed_data\")\n",
    "MOCK_GCS_MODEL_OUTPUT_PATH_PREFIX = os.path.join(MOCK_GCS_BASE_BUCKET, \"model_output\")\n",
    "MOCK_GCS_PREDICTION_OUTPUT_PATH = os.path.join(MOCK_GCS_BASE_BUCKET, \"prediction_output\")\n",
    "\n",
    "# Daily paths based on DATE_TO_PROCESS\n",
    "MOCK_INPUT_GCS_DAY_PATH = os.path.join(MOCK_GCS_RAW_DATA_PATH, DATE_TO_PROCESS) # Input for split_dataset\n",
    "MOCK_PROCESSED_DAY_PATH = os.path.join(MOCK_GCS_PROCESSED_DATA_PATH_PREFIX, DATE_TO_PROCESS)\n",
    "MOCK_MODEL_DIR_DAY_PATH = os.path.join(MOCK_GCS_MODEL_OUTPUT_PATH_PREFIX, DATE_TO_PROCESS)\n",
    "\n",
    "# Specific split paths (outputs of split_dataset, inputs for training)\n",
    "MOCK_GCS_TRAIN_DATA_PATH = os.path.join(MOCK_PROCESSED_DAY_PATH, \"train\")\n",
    "MOCK_GCS_EVAL_DATA_PATH = os.path.join(MOCK_PROCESSED_DAY_PATH, \"validation\")\n",
    "MOCK_GCS_TEST_DATA_PATH = os.path.join(MOCK_PROCESSED_DAY_PATH, \"test\") # Though not used in ESMM template\n",
    "\n",
    "# --- Config File Paths ---\n",
    "CONFIG_TEMPLATE_PATH = \"../configs/esmm_pipeline_template.config\"\n",
    "GENERATED_PIPELINE_CONFIG_PATH = f\"../configs/generated_pipeline_{DATE_TO_PROCESS}.config\"\n",
    "\n",
    "# --- Data Splitting Parameters ---\n",
    "TRAIN_FRACTION = 0.8\n",
    "VALIDATION_FRACTION = 0.1\n",
    "# Test fraction is 1.0 - TRAIN_FRACTION - VALIDATION_FRACTION\n",
    "\n",
    "# --- Schema Inference & Feature Engineering Params ---\n",
    "# load_sample_from_gcs_parquet will use its defaults: num_files_to_sample=1, num_rows_per_file_sample=1000\n",
    "\n",
    "# --- EasyRec Training Parameters (Overrides for template) ---\n",
    "TRAINING_PARAMS = {\n",
    "    \"batch_size\": 4096,\n",
    "    \"num_epochs\": 1, # Keep low for quick demo; increase for real training\n",
    "    \"learning_rate\": 0.0005,\n",
    "    \"save_checkpoints_steps\": 2000\n",
    "}\n",
    "\n",
    "# --- Evaluation Parameters ---\n",
    "MOCK_PREDICTION_FILE = os.path.join(MOCK_GCS_PREDICTION_OUTPUT_PATH, DATE_TO_PROCESS, \"predictions.parquet\")\n",
    "GROUP_BY_COLUMN_EVAL = \"user_id\"\n",
    "CLICK_LABEL_COLUMN = \"click\"\n",
    "CLICK_SCORE_COLUMN = \"click_prediction_score\" # Must match output of EasyRec predictor\n",
    "CONVERSION_LABEL_COLUMN = \"conversion\"\n",
    "CONVERSION_SCORE_COLUMN = \"conversion_prediction_score\" # Must match output of EasyRec predictor\n",
    "\n",
    "print(f\"Date to process: {DATE_TO_PROCESS}\")\n",
    "print(f\"Mock GCS Train data path for schema inference: {MOCK_GCS_TRAIN_DATA_PATH}\")\n",
    "print(f\"Generated pipeline config will be saved to: {os.path.abspath(GENERATED_PIPELINE_CONFIG_PATH)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Stage 1: Data Preparation - Splitting Daily Snapshot\n",
    "\n",
    "This stage simulates the `split_dataset.py` script. In a real scenario, this script would interact with GCS to:\n",
    "1. List all Parquet files for a given day (e.g., `gs://mock-bucket/raw_data/20231101/`).\n",
    "2. Read these Parquet files into a single DataFrame.\n",
    "3. Perform a row-level random split into train, validation, and test sets.\n",
    "4. Save these splits back to GCS (e.g., into `gs://mock-bucket/processed_data/20231101/train/`, `.../validation/`, `.../test/`).\n",
    "\n",
    "Here, we'll use the `perform_split` function directly with mock GCS functions that return sample DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Stage 1: Data Splitting (Simulated) ---\")\n",
    "# The perform_split function uses mock GCS read/list functions internally for this demo.\n",
    "# It will print messages about its (mock) GCS operations.\n",
    "train_df_sample, validation_df_sample, test_df_sample = perform_split(\n",
    "    input_gcs_day_path=MOCK_INPUT_GCS_DAY_PATH, \n",
    "    output_gcs_path_prefix=MOCK_GCS_PROCESSED_DATA_PATH_PREFIX, \n",
    "    train_fraction=TRAIN_FRACTION, \n",
    "    validation_fraction=VALIDATION_FRACTION, \n",
    "    random_seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "if train_df_sample is not None and not train_df_sample.empty:\n",
    "    print(\"\\nSuccessfully (mock) split data.\")\n",
    "    print(f\"Train sample shape: {train_df_sample.shape}\")\n",
    "    # train_df_sample.head()\n",
    "else:\n",
    "    print(\"\\nMock data splitting failed or returned empty train set. Using a fallback sample for next steps.\")\n",
    "    # Fallback to ensure notebook can proceed if mock split had issues or returned None\n",
    "    train_df_sample = get_sample_dataframe(num_rows=int(1000 * TRAIN_FRACTION))\n",
    "    validation_df_sample = get_sample_dataframe(num_rows=int(1000 * VALIDATION_FRACTION))\n",
    "    test_df_sample = get_sample_dataframe(num_rows=int(1000 * (1.0 - TRAIN_FRACTION - VALIDATION_FRACTION)))\n",
    "    print(f\"Fallback Train sample shape: {train_df_sample.shape}\")\n",
    "\n",
    "# For the next stage (schema inference), we need a DataFrame sample.\n",
    "# In a real scenario, load_sample_from_gcs_parquet would (mock) read from MOCK_GCS_TRAIN_DATA_PATH.\n",
    "# Here, we directly use the train_df_sample from the previous (mock) split if it's valid.\n",
    "df_for_schema_inference = train_df_sample \n",
    "if df_for_schema_inference.empty:\n",
    "    print(\"Warning: df_for_schema_inference is empty, using a default sample.\")\n",
    "    df_for_schema_inference = get_sample_dataframe(num_rows=200) # Ensure it's not empty for classify_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Stage 2: EasyRec Configuration Generation\n",
    "\n",
    "This stage uses the `train_df_sample` (conceptually from the GCS training split path) to:\n",
    "1. Infer feature types (`classify_features`).\n",
    "2. Generate `input_fields` and `feature_config` protobuf snippets.\n",
    "3. Automatically group features into 'user' and 'item' groups (`group_features`).\n",
    "4. Populate the `esmm_pipeline_template.config` using the refactored `populate_and_save_config` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Stage 2: EasyRec Configuration Generation ---\")\n",
    "\n",
    "# 1. Classify features from the training data sample\n",
    "print(\"Classifying features...\")\n",
    "classified_features = classify_features(df_for_schema_inference)\n",
    "print(f\"Classified features: {json.dumps(classified_features, indent=2)}\")\n",
    "\n",
    "# 2. Generate input_fields and feature_config protobuf snippets\n",
    "print(\"\\nGenerating protobuf snippets...\")\n",
    "input_fields_str = generate_input_fields_proto(classified_features)\n",
    "feature_config_str = generate_feature_config_proto(classified_features)\n",
    "# print(\"Input Fields Proto:\\n\", input_fields_str)\n",
    "# print(\"\\nFeature Config Proto:\\n\", feature_config_str)\n",
    "\n",
    "# 3. Automatically group features\n",
    "print(\"\\nGrouping features...\")\n",
    "grouped_features = group_features(classified_features)\n",
    "print(f\"Grouped features: {json.dumps(grouped_features, indent=2)}\")\n",
    "\n",
    "# 4. Prepare GCS paths and training parameters for config population\n",
    "gcs_paths_for_config = {\n",
    "    \"train\": MOCK_GCS_TRAIN_DATA_PATH + \"/\", # Ensure trailing slash for directory\n",
    "    \"eval\": MOCK_GCS_EVAL_DATA_PATH + \"/\",\n",
    "    \"model_dir\": MOCK_MODEL_DIR_DAY_PATH + \"/\"\n",
    "}\n",
    "\n",
    "# Create a Namespace object similar to what argparse would produce for training_params\n",
    "class ArgsNamespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "training_params_args = ArgsNamespace(**TRAINING_PARAMS)\n",
    "\n",
    "# 5. Populate and save the configuration file\n",
    "print(\"\\nPopulating and saving final pipeline configuration...\")\n",
    "generated_config_file = populate_and_save_config(\n",
    "    template_config_path=CONFIG_TEMPLATE_PATH,\n",
    "    output_config_path=GENERATED_PIPELINE_CONFIG_PATH,\n",
    "    input_fields_str=input_fields_str, # Already indented by auto_feature_config_generator's wrapper\n",
    "    feature_config_str=feature_config_str, # Already indented\n",
    "    grouped_features=grouped_features,\n",
    "    gcs_paths=gcs_paths_for_config,\n",
    "    cli_args=training_params_args # Pass the Namespace object\n",
    ")\n",
    "\n",
    "if generated_config_file:\n",
    "    print(f\"\\nGenerated EasyRec pipeline configuration saved to: {generated_config_file}\")\n",
    "    # Optional: Print a snippet of the generated config\n",
    "    # with open(generated_config_file, 'r') as f:\n",
    "    #     print(\"\\n--- Snippet of Generated Config ---\")\n",
    "    #     for _ in range(30): # Print first 30 lines\n",
    "    #         line = f.readline()\n",
    "    #         if not line: break\n",
    "    #         print(line, end='')\n",
    "    #     print(\"...\")\n",
    "else:\n",
    "    print(\"\\nFailed to generate pipeline configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Stage 3: Model Training (Simulated)\n",
    "\n",
    "This stage would involve executing the EasyRec training process using the configuration file generated in the previous step.\n",
    "\n",
    "**Important:** Running this requires a fully configured EasyRec environment, including TensorFlow and all necessary dependencies. The GCS paths in the generated config must also be accessible and contain appropriately formatted Parquet data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Stage 3: Model Training (Simulated) ---\")\n",
    "\n",
    "if generated_config_file and os.path.exists(generated_config_file):\n",
    "    abs_generated_config_path = os.path.abspath(generated_config_file)\n",
    "    training_command_parts = [\n",
    "        \"python\", \"-m\", \"easy_rec.python.train_eval\",\n",
    "        f\"--pipeline_config_path={abs_generated_config_path}\"\n",
    "    ]\n",
    "    training_command_str = \" \".join(training_command_parts)\n",
    "    \n",
    "    print(\"The following command would be run for EasyRec training:\")\n",
    "    print(f\"  {training_command_str}\")\n",
    "    \n",
    "    # To actually run it (uncomment and ensure EasyRec is installed):\n",
    "    # print(\"\\nSimulating training execution (will likely fail if EasyRec is not set up)...\\n\")\n",
    "    # try:\n",
    "    #     process_result = subprocess.run(training_command_parts, check=True, text=True, capture_output=True)\n",
    "    #     print(\"--- EasyRec Training STDOUT ---\")\n",
    "    #     print(process_result.stdout)\n",
    "    #     print(\"--- End of EasyRec Training STDOUT ---\")\n",
    "    #     print(\"\\nEasyRec training process completed successfully (simulated).\")\n",
    "    # except FileNotFoundError:\n",
    "    #     print(\"Error: 'python' or EasyRec module not found. Cannot execute training.\")\n",
    "    #     print(\"Please ensure your Python environment is set up correctly for EasyRec.\")\n",
    "    # except subprocess.CalledProcessError as e:\n",
    "    #     print(f\"Error during EasyRec training execution (return code {e.returncode}):\")\n",
    "    #     print(\"--- STDOUT ---\"); print(e.stdout)\n",
    "    #     print(\"--- STDERR ---\"); print(e.stderr)\n",
    "    #     print(\"EasyRec training failed (simulated).\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"An unexpected error occurred during simulated training: {e}\")\n",
    "    print(\"\\nNote: Actual training execution is commented out. Uncomment to try.\")\n",
    "else:\n",
    "    print(\"Generated config file not found. Skipping training simulation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Stage 4: Model Evaluation\n",
    "\n",
    "After training, predictions would be generated by EasyRec (either as part of evaluation or a separate prediction job). This stage uses the `evaluate_model.py` script to calculate Group AUC (GAUC) on these predictions.\n",
    "\n",
    "We'll first create a mock prediction file for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Stage 4: Model Evaluation (using mock predictions) ---\")\n",
    "\n",
    "# 1. Create a mock prediction file\n",
    "mock_prediction_dir = os.path.dirname(MOCK_PREDICTION_FILE)\n",
    "if not os.path.exists(mock_prediction_dir):\n",
    "    os.makedirs(mock_prediction_dir)\n",
    "    print(f\"Created directory for mock predictions: {mock_prediction_dir}\")\n",
    "\n",
    "create_mock_prediction_file(\n",
    "    file_path=MOCK_PREDICTION_FILE,\n",
    "    num_rows=2000, \n",
    "    num_groups=50,\n",
    "    group_col_name=GROUP_BY_COLUMN_EVAL,\n",
    "    click_label_col=CLICK_LABEL_COLUMN,\n",
    "    click_score_col=CLICK_SCORE_COLUMN,\n",
    "    conv_label_col=CONVERSION_LABEL_COLUMN,\n",
    "    conv_score_col=CONVERSION_SCORE_COLUMN,\n",
    "    file_type=\"parquet\"\n",
    ")\n",
    "\n",
    "# 2. Load the mock prediction data\n",
    "try:\n",
    "    df_predictions = pd.read_parquet(MOCK_PREDICTION_FILE)\n",
    "    print(f\"\\nSuccessfully loaded mock prediction data. Shape: {df_predictions.shape}\")\n",
    "    # print(df_predictions.head())\n",
    "\n",
    "    # 3. Calculate Group AUC for CTR\n",
    "    print(\"\\nCalculating GAUC for CTR...\")\n",
    "    gauc_ctr = calculate_group_auc(\n",
    "        df_predictions.copy(), \n",
    "        score_col=CLICK_SCORE_COLUMN, \n",
    "        label_col=CLICK_LABEL_COLUMN, \n",
    "        group_col=GROUP_BY_COLUMN_EVAL\n",
    "    )\n",
    "    if pd.notna(gauc_ctr):\n",
    "        print(f\"  GAUC (CTR) for '{GROUP_BY_COLUMN_EVAL}': {gauc_ctr:.6f}\")\n",
    "    else:\n",
    "        print(\"  GAUC (CTR) could not be calculated.\")\n",
    "\n",
    "    # 4. Calculate Group AUC for CVR (on clicked samples)\n",
    "    print(\"\\nCalculating GAUC for CVR (on clicked samples only)...\")\n",
    "    df_clicked_samples = df_predictions[df_predictions[CLICK_LABEL_COLUMN] == 1].copy()\n",
    "    if df_clicked_samples.empty:\n",
    "        print(\"  No samples with click=1 found. Cannot calculate GAUC for CVR.\")\n",
    "    else:\n",
    "        print(f\"  Evaluating CVR on {len(df_clicked_samples)} clicked samples.\")\n",
    "        gauc_cvr = calculate_group_auc(\n",
    "            df_clicked_samples, \n",
    "            score_col=CONVERSION_SCORE_COLUMN, \n",
    "            label_col=CONVERSION_LABEL_COLUMN, \n",
    "            group_col=GROUP_BY_COLUMN_EVAL\n",
    "        )\n",
    "        if pd.notna(gauc_cvr):\n",
    "            print(f\"  GAUC (CVR) for '{GROUP_BY_COLUMN_EVAL}': {gauc_cvr:.6f}\")\n",
    "        else:\n",
    "            print(\"  GAUC (CVR) could not be calculated.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Mock prediction file not found at {MOCK_PREDICTION_FILE}. Cannot perform evaluation.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during evaluation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Conclusion\n",
    "\n",
    "This notebook provided an orchestrated walkthrough of the ESMM recommender pipeline using the developed Python scripts. Key takeaways:\n",
    "- Data splitting is simulated, preparing distinct datasets for training, validation (and potentially test).\n",
    "- Feature configuration (`input_fields`, `feature_config`) and feature grouping for EasyRec are automated based on a sample of the training data.\n",
    "- A complete EasyRec pipeline configuration file is generated by populating a template with these auto-generated sections, GCS paths, and training parameters.\n",
    "- The process for invoking EasyRec training with the generated config is outlined.\n",
    "- Offline evaluation using Group AUC on (mock) model predictions is demonstrated for both CTR and CVR tasks.\n",
    "\n",
    "**Next Steps for Real Execution:**\n",
    "1.  Replace all mock GCS paths with actual GCS locations for your raw data, processed data, model outputs, and predictions.\n",
    "2.  Implement the actual GCS read/write logic within the mock functions in `split_dataset.py` and `auto_feature_config_generator.py` (or replace calls to mocks with direct GCS operations if preferred).\n",
    "3.  Ensure your environment has EasyRec, TensorFlow, and all other necessary dependencies installed correctly.\n",
    "4.  Execute the EasyRec training using the generated configuration file.\n",
    "5.  Generate actual prediction outputs from your trained EasyRec model.\n",
    "6.  Use `evaluate_model.py` with the path to your actual prediction file to get GAUC scores and other relevant metrics provided by EasyRec's evaluation logs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
