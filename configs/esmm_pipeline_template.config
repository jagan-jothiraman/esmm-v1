# EasyRec ESMM Pipeline Configuration Template

# Input Paths - Placeholders to be replaced by the generation script
train_input_path: "gs://<YOUR_BUCKET>/<YOUR_PROCESSED_DATA_PATH>/<YYYYMMDD>/train/"
eval_input_path: "gs://<YOUR_BUCKET>/<YOUR_PROCESSED_DATA_PATH>/<YYYYMMDD>/validation/"

# Model Directory - Placeholder
model_dir: "gs://<YOUR_BUCKET>/<YOUR_MODEL_OUTPUT_PATH>/<YYYYMMDD>/"

data_config {
  # input_fields will be populated by the auto-generator script
  #<INPUT_FIELDS_PLACEHOLDER>

  label_fields: "click"       # Primary label for CTR task
  label_fields: "conversion"  # Primary label for CVR task (post-click conversion)
  batch_size: 4096            # Default, can be overridden
  num_epochs: 1               # Default, can be overridden
  prefetch_size: 32
  # input_type: HiveParquetInput # Assuming direct Parquet reading capability.
                               # Might need to be ParquetInput or CSVInput depending on EasyRec/TF version
                               # and how GCS paths with wildcards are handled.
                               # For now, relying on auto-detection or simple Parquet if possible.
  input_type: ParquetInput # More standard for direct Parquet reading
}

feature_config {
  # features will be populated by the auto-generator script
  #<FEATURE_CONFIG_PLACEHOLDER>
}

train_config {
  optimizer_config {
    optimizer: {
      adam_optimizer {
        learning_rate: {
          constant_learning_rate {
            learning_rate: 0.0005 # Default, can be overridden
          }
        }
      }
    }
    use_moving_average: false
  }
  log_step_count_steps: 100
  save_checkpoints_steps: 1000 # Default, can be overridden
  # num_steps: 0 # Set to 0 to train for num_epochs, or set to a specific number of steps
}

eval_config {
  metrics_set {
    key: "auc_and_recall" # Combined key for standard metrics
    value {
      auc {}
      recall_at_top_k { top_k: [10, 50, 100] }
      # Other metrics like PrecisionAtTopK could also be added here.
    }
  }
  # eval_interval_secs: 600 # How often to run evaluation during training. Default is 300.
  # num_examples: 0 # Evaluate on all examples in eval_input_path. Default is all.
  # eval_online_config {} # For online evaluation if needed.
}

export_config {
  # Configuration for exporting the model, e.g., for TensorFlow Serving
  # exporter {
  #   dump_model_path: "gs://<YOUR_BUCKET>/<YOUR_MODEL_DUMP_PATH>/<YYYYMMDD>/" (placeholder)
  #   latest_exporter {}
  # }
}

model_config {
  model_class: "ESMM"
  feature_groups {
    group_name: "user"
    feature_names: "#<USER_FEATURES_PLACEHOLDER>" # e.g. "user_id", "user_age_group", "user_gender"
                                                 # To be populated or refined by generation script
  }
  feature_groups {
    group_name: "item"
    feature_names: "#<ITEM_FEATURES_PLACEHOLDER>" # e.g. "item_id", "item_category", "item_brand"
                                                 # To be populated or refined by generation script
  }
  # Add other feature groups if necessary, e.g., context features

  esmm {
    user_tower {
      dnn {
        hidden_units: [256, 128, 64]
        # activation: RELU
        # use_bias: true
        # dropout_ratio: 0.1
      }
      input: "user" # Corresponds to feature_group name
    }
    item_tower {
      dnn {
        hidden_units: [256, 128, 64]
      }
      input: "item" # Corresponds to feature_group name
    }
    ctr_tower {
      label_name: "click"
      dnn {
        hidden_units: [128, 64]
        # output_dim: 1 # Default for classification
      }
    }
    cvr_tower {
      label_name: "conversion"
      dnn {
        hidden_units: [128, 64]
        # output_dim: 1 # Default for classification
      }
    }
    l2_regularization: 0.00001 # Default, can be overridden
    embedding_regularization: 0.00001 # Default, can be overridden
  }
}
